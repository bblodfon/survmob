% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SurvLPS.R
\name{SurvLPS}
\alias{SurvLPS}
\title{Survival Learners and Parameter Spaces}
\description{
Convenient \link[R6:R6Class]{R6} class that offers methods to retrieve
the survival learners that will be used for benchmarking as well as suggested
hyperparameter spaces for those learners.
}
\examples{
library(paradox)
library(mlr3proba)
library(mlr3extralearners)

s = SurvLPS$new(nthreads_rsf = 4)

# All available learner ids
s$lrn_ids()

# Get all parameter spaces
pss = s$pss()

# CoxPH doesn't have hyperparameters to tune
pss$coxph
# random survival forest hyperparameter space
pss$rsf_logrank
# XGBoost hyperparameter space with early stopping
pss$xgboost_cox_early$trafo(x = list(
  XGBoostCox.nrounds = 150,
  XGBoostCox.eta = -5,
  XGBoostCox.max_depth = 5))
# XGBoost AFT hyperparameter space with additional
# regularization parameters
pss$xgboost_aft_reg

# Get only 2 learner objects
s$initialize(ids = c('coxnet', 'coxboost'))
s$lrns()

# Get a convenient data table format
dt = s$lrn_tbl()
dt

}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{nthreads_rsf}}{(\code{int(1)})\cr
Number of cores to use in the random forest survival learners}

\item{\code{nthreads_xgb}}{(\code{int(1)})\cr
Number of cores to use in the xgboost survival learners}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-SurvLPS-new}{\code{SurvLPS$new()}}
\item \href{#method-SurvLPS-lrn_ids}{\code{SurvLPS$lrn_ids()}}
\item \href{#method-SurvLPS-lrn_tbl}{\code{SurvLPS$lrn_tbl()}}
\item \href{#method-SurvLPS-lrns}{\code{SurvLPS$lrns()}}
\item \href{#method-SurvLPS-pss}{\code{SurvLPS$pss()}}
\item \href{#method-SurvLPS-help}{\code{SurvLPS$help()}}
\item \href{#method-SurvLPS-clone}{\code{SurvLPS$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-SurvLPS-new"></a>}}
\if{latex}{\out{\hypertarget{method-SurvLPS-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \link[R6:R6Class]{R6} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SurvLPS$new(
  ids = NULL,
  nthreads_rsf = unname(parallelly::availableCores()),
  nthreads_xgb = 1
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{ids}}{(\code{character()})\cr
Survival learner ids for which to request the corresponding
\link[mlr3proba:LearnerSurv]{LearnerSurv} objects and suggested
hyperparameter spaces.
If not provided, the other methods of this class will return objects
which will include all learners currently supported.
See method \code{get_lrns_ids()} for available ids to request.}

\item{\code{nthreads_rsf}}{(\code{int(1)})\cr
Number of cores to use in random survival forest learners (implicit
parallelization). Default value: use all available cores.}

\item{\code{nthreads_xgb}}{(\code{int(1)})\cr
Number of cores to use in xgboost survival learners (implicit
parallelization). Default value: use 1 core.}
}
\if{html}{\out{</div>}}
}
\subsection{Details}{
If implicit parallelization is desired, the more \code{nthreads_rsf}
the better, but that is not the case with the xgboost learners.
With xgboost, adding more cores (especially when training small datasets)
might create performance issues, so test before you use too many \code{nthreads_xgb}!
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-SurvLPS-lrn_ids"></a>}}
\if{latex}{\out{\hypertarget{method-SurvLPS-lrn_ids}{}}}
\subsection{Method \code{lrn_ids()}}{
Survival Learners IDs
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SurvLPS$lrn_ids()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
(\code{character()})\cr
A vector of ALL available survival learner ids
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-SurvLPS-lrn_tbl"></a>}}
\if{latex}{\out{\hypertarget{method-SurvLPS-lrn_tbl}{}}}
\subsection{Method \code{lrn_tbl()}}{
Survival learners table
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SurvLPS$lrn_tbl()}\if{html}{\out{</div>}}
}

\subsection{Details}{
This function uses \code{lrns()} and \code{pss()} methods to return a
data table of available survival learners and tuning parameters for each.
}

\subsection{Returns}{
a \link[data.table:data.table]{data.table::data.table} with 3 columns:
\enumerate{
\item \code{id}: learner id
\item \code{learner}: an \link[mlr3proba:LearnerSurv]{mlr3proba::LearnerSurv} object
\item \code{param_set}: a \link[paradox:ParamSet]{paradox::ParamSet} object to be used for tuning each
respective survival learner
}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-SurvLPS-lrns"></a>}}
\if{latex}{\out{\hypertarget{method-SurvLPS-lrns}{}}}
\subsection{Method \code{lrns()}}{
Survival Learners
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SurvLPS$lrns()}\if{html}{\out{</div>}}
}

\subsection{Details}{
\itemize{
\item All learners return the prediction types \code{crank} and \code{distr} (so that
both discrimination and calibration performance measures can be used)
\item The CoxPH and CoxBoost learners return \code{distr} prediction by applying a
transformation on the \code{lp} prediction using the Breslow estimator (as is
done by default from the respective packages - we don't change anything)
\item The \code{SurvivalTree}, \code{CoxNet}, \code{XGBoostCox} and \code{XGBoostAFT} learners
return a \code{distr} prediction by transforming it from the \code{crank}
prediction (the latter being equal to \code{lp} if the learner returns it)
using the \link[mlr3proba:mlr_graphs_distrcompositor]{mlr3proba::distrcompositor}.
}
}

\subsection{Returns}{
(\code{list()})\cr
A list of mlr3 survival learners able to predict both \code{crank}/
\code{lp} (ranks) and \code{distr} predictions (survival probabilities) on test
data.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-SurvLPS-pss"></a>}}
\if{latex}{\out{\hypertarget{method-SurvLPS-pss}{}}}
\subsection{Method \code{pss()}}{
Suggested Parameter Spaces
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SurvLPS$pss()}\if{html}{\out{</div>}}
}

\subsection{Details}{
For the XGBoostCox learner, we provide:
\enumerate{
\item A basic parameter space with 4 hyperparameters
\item The above 4 hyperparameters + support of early stopping (10\% of the
\code{nrounds})
\item The basic 4 hyperparameters + 3 regularization hyperparameters.
}

The above 3 parameter spaces are also offered for the XGBoostAFT learner with
the addition of 2 more hyperparameter to tune. See examples.
}

\subsection{Returns}{
(\code{list()})\cr
A list with suggested \code{\link[paradox:ps]{paradox::ps()}} objects (to be used for tuning)
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-SurvLPS-help"></a>}}
\if{latex}{\out{\hypertarget{method-SurvLPS-help}{}}}
\subsection{Method \code{help()}}{
Opens the help page for this object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SurvLPS$help()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-SurvLPS-clone"></a>}}
\if{latex}{\out{\hypertarget{method-SurvLPS-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SurvLPS$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
